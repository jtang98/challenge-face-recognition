{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras-SD210-contreTous.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Challenge SD-TSIA210\n",
        "\n",
        "## TANG Joël & TORRES Claudia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fANF7EcThjkT",
        "colab_type": "code",
        "outputId": "6f9ef3b5-220b-41be-c0d2-bcccdf6ae079",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "))\n",
        "\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import plit"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using tensorflow version 2.2.0-rc2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpXgFgD5Y2yW",
        "colab_type": "code",
        "outputId": "3f20bf80-ef5a-4c98-8f45-19a0f321982e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#%%\n",
        "# Load training data\n",
        "\n",
        "nrows_train = 1068504\n",
        "nrows_test = 0\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "root_dir = \"/content/gdrive/My Drive/\"\n",
        "\n",
        "xtrain = np.loadtxt(root_dir + 'xtrain_challenge.csv', delimiter=',', skiprows = 1, max_rows = nrows_train + nrows_test)\n",
        "ytrain = np.loadtxt(root_dir + 'ytrain_challenge.csv', delimiter=',', skiprows = 1, max_rows = nrows_train + nrows_test)\n",
        "ytrain = np.array(ytrain).reshape(nrows_train + nrows_test)\n",
        "# Check the number of observations and properties\n",
        "#print(xtrain[:3,])\n",
        "#print(ytrain[:10])\n",
        "#print(xtrain.shape)\n",
        "#print(ytrain.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the cell below, we perform data augmentation techniques.\n",
        "\n",
        "Our algorithm (decision trees) doesn't require scaled data, and allow their range to be heterogeneous. However, we can still mirror the data: since each sample is composed of two faces, and a certain range of features is separable with respect to one of the two faces, we can simply exchange them. This increases the size of the training set by a 2 factor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA2DgV5BY9Hm",
        "colab_type": "code",
        "outputId": "c97f3a6b-8ff3-460e-cdf0-d9900fc5776d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "6:]\n",
        "xtrain = xtrain.astype('float32')\n",
        "xtest = np.loadtxt(root_dir + 'xtest_challenge.csv', delimiter=',', skiprows = 1).astype('floatain)\n",
        "\n",
        "x_train_permuter = np.copy(xtrain)\n",
        "x_train_permuter[:, :13] = xtrain[:, 13:26]\n",
        "x_train_permuter[:, 13:26] = xtrain[:, :13]\n",
        "\n",
        "new_x_train = np.concatenate((xtrain, x_train_permuter), axis=0)\n",
        "new_y_train = np.concatenate((ytrain, ytrain), axisain)\n",
        "xtrain_preprocessed = xtest)\n",
        "xtest_preprocessextest\n",
        "KAZE\n",
        "print(xtrain_preprocessed.shape)\n",
        "print(ytrain.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1068504, 37)\n",
            "(1068504,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "wDMZ8y57il9B"
      },
      "source": [
        "In the code cell below we apply cross-validation on the XGBClassifier model. We boost the learning of many decision trees which are considered as weak leaners.\n",
        "The most important parameters are :\n",
        "- learning_rate: similar to other gradient descent methods, the classifier perform more or less a gradient correction. A small learning rate will lead to very slow convergence, a big learning rate can make us miss the sweet spot.\n",
        "- n_estimators: to be considered as a trade-off with the learning rate. It is the number of rounds performed by the classifier during learning. A too great number will lead to over-fitting.\n",
        "- max_depth: the maximum depth related to the decision trees. The less it is, the more the decision trees are basic (hence having higher bias, which is not a problem for boosting)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY0OPTMiOC-v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "874f8edc-343c-4084-81e2-5c81c925ddc8"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "    boost = XGBClassifier(base_score=0.45, colsample_bylevel=1, colsample_bytree=1,max_depth=6,\n",
        "                          gamma=0, learning_rate=0.25, max_delta_step=0,\n",
        "                          min_child_weight=1, missing=None, n_estimators=675, nthread=-1,\n",
        "                          objective='binary:logistic', sampling_method='gradient_based',\n",
        "                          reg_alpha=0, reg_lambda=1, tree_method='gpu_hist',\n",
        "                          scale_pos_weight=1.002, silent=True, subsample=1)\n",
        "  \n",
        "    p_grid_boost = {'gamma': [0.5, 1, 1.5, 2],\n",
        "                    'reg_lambda': [1.5, 2, 2.5, 3],\n",
        "                    'colsample_bytree': [0.7, 0.85, 1.0],\n",
        "                    'base_score': [0.45, 0.5],\n",
        "                    'n_estimators': [650,655,660,665,670,675,680,685,690,695,700],\n",
        "                    'learning_rate': [0.15, 0.2, 0.25,0.35]\n",
        "                    }   \n",
        "\n",
        "    grid_boost = RandomizedSearchCV(estimator=boost, param_distributions=p_grid_boost, scoring=\"accuracy\", cv=5, verbose=3)\n",
        "  \n",
        "    grid_boost.fit(xtrain_preprocessed, ytrain)\n",
        "\n",
        "    print(\"Best Score: {}\".format(grid_boost.best_score_))\n",
        "    print(\"Best params: {}\".format(grid_boost.best_params_))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Score: 0.9990847015822186\n",
            "Best params: {'max_depth': 6, 'n_estimators': 700}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maMpQLxXPaI2",
        "colab_type": "code",
        "outputId": "3817ecac-98d5-4543-ab28-bffa3123b465",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "boost = XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
        "                      gamma=0, learning_rate=0.25, max_delta_step=0, max_depth=6,\n",
        "                      min_child_weight=1, missing=None, n_estimators=700, nthread=-1,\n",
        "                      objective='binary:logistic', sampling_method='gradient_based',\n",
        "                      reg_alpha=0, reg_lambda=1, tree_method='gpu_hist',\n",
        "                      scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
        "boost.fit(new_x_train, new_y_train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.25, max_delta_step=0, max_depth=6,\n",
              "              min_child_weight=1, missing=None, n_estimators=700, n_jobs=1,\n",
              "              nthread=-1, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, sampling_method='gradient_based',\n",
              "              scale_pos_weight=1, seed=0, silent=True, subsample=1,\n",
              "              tree_method='gpu_hist', verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_-949YbQWQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = boost.predict(xtest_preprocessed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIxo19DJRm50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.savetxt(root_dir + 'ytest_challenge_student_cv.csv', output, fmt = '%1.0d', delimiter=',')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}